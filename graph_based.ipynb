{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfed2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "import sys\n",
    "import dimod \n",
    "import dwave_networkx as dnx\n",
    "import metis\n",
    "####\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import neal\n",
    "import dwave.inspector\n",
    "\n",
    "hed=list(range(0,26))\n",
    "\n",
    "df=pd.read_csv(\"./metis_graph_weights_002.dat\",skiprows=[0],header=None,sep=\" \")\n",
    "dh=pd.read_csv(\"./metis_graph_simple_002.dat\",skiprows=[0],header=None,sep=\" \")\n",
    "dtt=pd.read_csv(\"./metis_graph_std_002.dat\",skiprows=[0],header=None,sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise Data\n",
    "max_value1 = df.max(skipna=True).max()\n",
    "df=df/max_value1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24e072",
   "metadata": {},
   "source": [
    "## Map Metis output to graph suitable for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad49570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df--->Weight list\n",
    "#dh--->Link list\n",
    "\n",
    "# [0,....]\n",
    "# [1,....]\n",
    "# [2,....]\n",
    "d=[]\n",
    "e=[]\n",
    "w=[]\n",
    "d_f=[]\n",
    "e_f=[]\n",
    "for i in range(0,27):\n",
    "    for j in range(1,27):\n",
    "        d.append(i)\n",
    "        e.append(dh.iloc[i,j])\n",
    "        w.append(df.iloc[i,j+1])\n",
    "\n",
    "gp=pd.DataFrame()\n",
    "gp[\"s\"]=d\n",
    "gp[\"t\"]=e\n",
    "gp[\"w\"]=w\n",
    "gp[\"t\"]=gp[\"t\"]-1\n",
    "gp=gp[gp[\"s\"]<gp[\"t\"]] \n",
    "\n",
    "\n",
    "G=nx.from_pandas_edgelist(gp,source=\"s\",target=\"t\")\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "#nx.degree(G)\n",
    "nx.is_weighted(G) #i.e. not weighted yet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9188bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###This manually adds the correct weight to each edge combination\n",
    "\n",
    "for y,z in G.edges:\n",
    "    #a=gp[(gp[\"s\"]==y) & (gp[\"t\"]==z)].index.values\n",
    "    a=gp[( (gp[\"s\"]==y) & (gp[\"t\"]==z) ) | ( (gp[\"s\"]==z) & (gp[\"t\"]==y) ) ].index.values  #Not unique \n",
    "   # ll=gp[\"w\"].loc[a].values            #original\n",
    "    ll = gp[\"w\"].loc[a].values.flatten() #try debug for adjacency matrix\n",
    "    G[y][z][\"weight\"]=ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually add node weights\n",
    "node_ids = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "weights = df[1].tolist()\n",
    "\n",
    "for node, weight in zip(node_ids, weights):\n",
    "    if G.has_node(node):\n",
    "        G.nodes[node]['weight'] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_weighted(G) #debug check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a242ed",
   "metadata": {},
   "source": [
    "## MEtis Cut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metis cut\n",
    "%time\n",
    "(edgecuts, parts) = metis.part_graph(G, 2,)\n",
    "\n",
    "cut_weight = 0\n",
    "####Cut weights\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if parts[u] != parts[v]:\n",
    "        cut_weight += data['weight']\n",
    "\n",
    "print('cut edges',cut_weight)\n",
    "\n",
    "####Partition weights\n",
    "partition_weights = defaultdict(int)\n",
    "\n",
    "for node, data in G.nodes(data=True):\n",
    "    partition_label = parts[node]\n",
    "    node_weight = data.get('weight',)  \n",
    "    partition_weights[partition_label] += node_weight\n",
    "\n",
    "print('partition weights',partition_weights)\n",
    "metis_node= abs(partition_weights[1]-partition_weights[0])/(0.5*(partition_weights[0]+partition_weights[1]))\n",
    "metis_edge=cut_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c055af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot Graph STructure\n",
    "node_colors = []\n",
    "for node in G.nodes():\n",
    "    if parts[node] == 0:\n",
    "        node_colors.append('#1f78b4')\n",
    "    else:\n",
    "        node_colors.append('#e31a1c')\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.circular_layout(G)  # positions for all nodes; you can use other layouts as well\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=500)\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)\n",
    "nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "# Highlight the cut edges \n",
    "cut_edge_list = [(u, v) for u, v, data in G.edges(data=True) if parts[u] != parts[v]]\n",
    "nx.draw_networkx_edges(G, pos, edgelist=cut_edge_list, width=2, alpha=0.5, edge_color=\"r\", style=\"dashed\")\n",
    "\n",
    "plt.title(\"Graph Partition Visualization (METIS)\")\n",
    "plt.axis('off')  # Turn off the axis\n",
    "\n",
    "#plt.savefig(\"gen1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a18284",
   "metadata": {},
   "outputs": [],
   "source": [
    "                      ##Can Run this block after QA to get same plot as above but using QA instead of Metis \n",
    "#import matplotlib.pyplot as plt\n",
    "#import networkx as nx\n",
    "#import numpy as np\n",
    "\n",
    "## Sort nodes by their label or any other criterion you have\n",
    "#sorted_nodes = sorted(G.nodes(), key=lambda x: x)  # Adjust if your sorting criterion is different\n",
    "\n",
    "## Calculate positions - starting with node 0 at the top\n",
    "#n = len(sorted_nodes)\n",
    "#pos = {node: (np.cos(2 * np.pi * i / n + np.pi/2), np.sin(2 * np.pi * i / n + np.pi/2)) for i, node in enumerate(sorted_nodes)}\n",
    "\n",
    "## Define node colors based on partitions\n",
    "#node_colors = ['#1f78b4' if parts[node] == 0 else '#e31a1c' for node in sorted_nodes]\n",
    "\n",
    "## Draw the graph nodes, edges, and labels using the calculated positions\n",
    "#nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=500)\n",
    "#nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)\n",
    "#nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "## Highlight the cut edges\n",
    "#cut_edge_list = [(u, v) for u, v in G.edges() if parts[u] != parts[v]]\n",
    "#nx.draw_networkx_edges(G, pos, edgelist=cut_edge_list, width=2, alpha=0.5, edge_color=\"r\", style=\"dashed\")\n",
    "\n",
    "##plt.title(\"Graph Partition Visualization\")\n",
    "#plt.axis('off')  \n",
    "#plt.tight_layout\n",
    "#plt.savefig(\"gen1.pdf\", format='pdf', bbox_inches='tight', pad_inches=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10592f9",
   "metadata": {},
   "source": [
    "## QA Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7718fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Unweighted Cut - Single Run (Debugging)-------\n",
    "num_reads = 1000\n",
    "gamma = 80\n",
    "\n",
    "Q = defaultdict(int)\n",
    "\n",
    "# Fill in Q matrix\n",
    "for u, v in G.edges:\n",
    "    Q[(u,u)] += 1\n",
    "    Q[(v,v)] += 1\n",
    "    Q[(u,v)] += -2\n",
    "\n",
    "for i in G.nodes:\n",
    "    Q[(i,i)] += gamma*(1-len(G.nodes))\n",
    "\n",
    "for i, j in combinations(G.nodes, 2):\n",
    "\tQ[(i,j)] += 2*gamma\n",
    "\n",
    "# ------- Run \n",
    "\n",
    "# Set chain strength\n",
    "chain_strength = gamma*len(G.nodes)\n",
    "\n",
    "\n",
    "sampler = EmbeddingComposite(DWaveSampler())\n",
    "response = sampler.sample_qubo(Q,\n",
    "                               chain_strength=chain_strength,\n",
    "                               num_reads=num_reads,\n",
    "                               label='GP')\n",
    "\n",
    "#Isolate best solution\n",
    "sample = response.record.sample[0]\n",
    "\n",
    "# In the case when n is odd, the set may have one more or one fewer nodes\n",
    "if sum(sample) in [math.floor(len(G.nodes)/2), math.ceil(len(G.nodes)/2)]:\n",
    "    num_cut_edges = 0\n",
    "    for u, v in G.edges:\n",
    "        num_cut_edges += sample[u] + sample[v] - 2*sample[u]*sample[v]\n",
    "    print(\"Valid partition found with\", num_cut_edges, \"cut edges.\")\n",
    "else:\n",
    "\n",
    "    print(\"Invalid partition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Weighted - Single run (Debugging)-------\n",
    "num_reads = 1000\n",
    "gamma = 1\n",
    "\n",
    "Q = defaultdict(int)\n",
    "\n",
    "# Fill in Q matrix\n",
    "for u, v in G.edges:\n",
    "    Q[(u,u)] += 1 * G[u][v][\"weight\"]\n",
    "    Q[(v,v)] += 1 * G[u][v][\"weight\"]\n",
    "    Q[(u,v)] += -2* G[u][v][\"weight\"]\n",
    "\n",
    "#for i in G.nodes:\n",
    "#    Q[(i,i)] += gamma*(1-len(G.nodes))*df.iloc[i,1]\n",
    "\n",
    "#for i, j in combinations(G.nodes, 2):\n",
    "#    Q[(i,j)] += 2*gamma*df.iloc[i,1]*df.iloc[j,1]\n",
    "\n",
    "for i in G.nodes:\n",
    "    Q[(i,i)] += gamma*(df.iloc[i,1]-df[1].sum())*df.iloc[i,1]\n",
    "\n",
    "for i, j in combinations(G.nodes, 2):\n",
    "    Q[(i,j)] += 2*gamma*df.iloc[i,1]*df.iloc[j,1]\n",
    "\n",
    "# ------- Run QUBO\n",
    "\n",
    "# Set chain strength\n",
    "chain_strength = 100*len(G.nodes)\n",
    "#chain_strength = g*len(G.nodes)\n",
    "# Run the QUBO\n",
    "sampler = EmbeddingComposite(DWaveSampler(token='')) #add token\n",
    "response = sampler.sample_qubo(Q,\n",
    "                               chain_strength=chain_strength,\n",
    "                               num_reads=num_reads,\n",
    "                               label= 'Graph Partitioning')\n",
    "\n",
    "\n",
    "# See if the best solution found is feasible, and if so print the number of cut edges.\n",
    "sample = response.record.sample[0]\n",
    "\n",
    "# In the case when n is odd, the set may have one more or one fewer nodes\n",
    "\n",
    "num_cut_edges = 0\n",
    "for u, v in G.edges:\n",
    "      num_cut_edges += sample[u] + sample[v] - 2*sample[u]*sample[v]\n",
    "print(\"Valid partition found with\", num_cut_edges, \"cut edges.\")\n",
    "total_cut_weight = 0\n",
    "for u, v in G.edges:\n",
    "    if sample[u] != sample[v]:  # If the two nodes of the edge are in different partitions\n",
    "          total_cut_weight += G[u][v][\"weight\"]  # Add the weight of the edge\n",
    "print(\"Valid partition found with cut edges of total weight:\", total_cut_weight)\n",
    "\n",
    "#dwave.inspector.show(response)       \n",
    "d_output=response.to_pandas_dataframe()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running weighted cut  multiple times for averages\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "from dwave.system import DWaveSampler, EmbeddingComposite\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize variables for averaging\n",
    "total_cut_weight_accumulated = 0\n",
    "total_weight_partition1_accumulated = 0\n",
    "total_weight_partition2_accumulated = 0\n",
    "num_iterations = 5\n",
    "\n",
    "# Run the code 5 times\n",
    "for _ in range(num_iterations):\n",
    "    num_reads = 1000\n",
    "    gamma = 1\n",
    "\n",
    "    Q = defaultdict(int)\n",
    "\n",
    "    # Fill in Q matrix\n",
    "    # Fill in Q matrix\n",
    "    for u, v in G.edges:\n",
    "        Q[(u,u)] += 1 * G[u][v][\"weight\"]\n",
    "        Q[(v,v)] += 1 * G[u][v][\"weight\"]\n",
    "        Q[(u,v)] += -2* G[u][v][\"weight\"]\n",
    "    for i in G.nodes:\n",
    "        Q[(i,i)] += gamma*(df.iloc[i,1]-df[1].sum())*df.iloc[i,1]\n",
    "\n",
    "    for i, j in combinations(G.nodes, 2):\n",
    "        Q[(i,j)] += 2*gamma*df.iloc[i,1]*df.iloc[j,1]\n",
    "\n",
    "    # Set chain strength and run the QUBO on the solver\n",
    "    chain_strength = 100 * len(G.nodes)\n",
    "    sampler = EmbeddingComposite(DWaveSampler(token='')) # Add your token \n",
    "    response = sampler.sample_qubo(Q, chain_strength=chain_strength, num_reads=num_reads)\n",
    "\n",
    "    sample = response.record.sample[0]\n",
    "\n",
    "    # Calculate cut edges and total cut weight\n",
    "    total_cut_weight = 0\n",
    "    for u, v in G.edges:\n",
    "        if sample[u] != sample[v]:\n",
    "            total_cut_weight += G[u][v][\"weight\"]\n",
    "\n",
    "    # Accumulate total cut weight\n",
    "    total_cut_weight_accumulated += total_cut_weight\n",
    "\n",
    "    # Calculate and accumulate partition weights\n",
    "    partition1_weight = sum(G.nodes[n]['weight'] for n in G if sample[n] == 0)\n",
    "    partition2_weight = sum(G.nodes[n]['weight'] for n in G if sample[n] == 1)\n",
    "    total_weight_partition1_accumulated += partition1_weight\n",
    "    total_weight_partition2_accumulated += partition2_weight\n",
    "\n",
    "# Calculate averages\n",
    "average_cut_weight = total_cut_weight_accumulated / num_iterations\n",
    "average_partition1_weight = total_weight_partition1_accumulated / num_iterations\n",
    "average_partition2_weight = total_weight_partition2_accumulated / num_iterations\n",
    "\n",
    "print(\"Average cut edges weight:\", average_cut_weight)\n",
    "print(\"Average weight of partition 1:\", average_partition1_weight)\n",
    "print(\"Average weight of partition 2:\", average_partition2_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore (sanity check)\n",
    "#a1=9.700231\n",
    "#a2=10.268669\n",
    "#abs(a1-a2)/(0.5*(a1+a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd767b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check size of partitions\n",
    "# Initialize partition weights\n",
    "partition_0_weight = 0\n",
    "partition_1_weight = 0\n",
    "\n",
    "# Calculate partition weights\n",
    "for node in G.nodes:\n",
    "    if sample[node] == 0:\n",
    "        partition_0_weight += G.nodes[node]['weight']\n",
    "    else:\n",
    "        partition_1_weight += G.nodes[node]['weight']\n",
    "\n",
    "print(\"Weight of partition 0:\", partition_0_weight)\n",
    "print(\"Weight of partition 1:\", partition_1_weight)\n",
    "#qa_node=abs(partition_0_weight-partition_1_weight) / (0.5*(partition_0_weight+partition_1_weight))\n",
    "#qa_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ac6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn\n",
    "# Create a matrix to store the weights of cut edges\n",
    "matrix = np.zeros((len(G.nodes()), len(G.nodes())))\n",
    "count_qa=0\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if sample[u] != sample[v]:  # Check if the edge is a cut edge\n",
    "        matrix[u-1][v-1] = data['weight']\n",
    "        matrix[v-1][u-1] = data['weight']  \n",
    "        count_qa+=1\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, cmap='viridis')\n",
    "#plt.savefig('heat_qa.pdf')\n",
    "plt.show()\n",
    "count_qa #check number of cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2751d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METIS\n",
    "# Create a matrix to store the weights of cut edges\n",
    "matrix = np.zeros((len(G.nodes()), len(G.nodes())))\n",
    "count_metis=0\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if parts[u] != parts[v]:  # Check if the edge is a cut edge\n",
    "        matrix[u-1][v-1] = data['weight']\n",
    "        matrix[v-1][u-1] = data['weight'] \n",
    "        count_metis+=1\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, cmap='viridis')\n",
    "#plt.savefig('heat_metis.pdf')\n",
    "plt.show()\n",
    "count_metis #check number of cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ff33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Weighted to find cbf change with gamma -------\n",
    "\n",
    "num_reads = 1000\n",
    "gammas = [0.1, 0.5, 1, 10, 100,500]  # adjust this list as needed\n",
    "mean_chain_break_fractions = []\n",
    "num_runs_per_gamma = 5\n",
    "\n",
    "for gamma in gammas:\n",
    "    chain_break_fractions_for_this_gamma = []\n",
    "\n",
    "    for _ in range(num_runs_per_gamma):\n",
    "        Q = defaultdict(int)\n",
    "\n",
    "        # Fill in Q matrix\n",
    "        for u, v in G.edges:\n",
    "            Q[(u, u)] += 1 * G[u][v][\"weight\"]\n",
    "            Q[(v, v)] += 1 * G[u][v][\"weight\"]\n",
    "            Q[(u, v)] += -2 * G[u][v][\"weight\"]\n",
    "\n",
    "        for i in G.nodes:\n",
    "            Q[(i, i)] += gamma * (df.iloc[i, 1] - df[1].sum()) * df.iloc[i, 1]\n",
    "\n",
    "        for i, j in combinations(G.nodes, 2):\n",
    "            Q[(i, j)] += 2 * gamma * df.iloc[i, 1] * df.iloc[j, 1]\n",
    "\n",
    "        # Set chain strength\n",
    "        #chain_strength = 100 * len(G.nodes)\n",
    "\n",
    "        # Run the QUBO on the solver\n",
    "        sampler = EmbeddingComposite(DWaveSampler(token='')) # Add your token\n",
    "        #response = sampler.sample_qubo(Q, chain_strength=chain_strength, num_reads=num_reads, label='Graph Partitioning')\n",
    "        response = sampler.sample_qubo(Q, num_reads=num_reads, label='Graph Partitioning')\n",
    "        # Calculate mean chain break fraction for this run\n",
    "        mean_chain_break_fraction_for_this_run = sum(response.record.chain_break_fraction) / len(response.record.chain_break_fraction)\n",
    "        chain_break_fractions_for_this_gamma.append(mean_chain_break_fraction_for_this_run)\n",
    "\n",
    "    # Calculate the average chain break fraction for this gamma over all runs\n",
    "    avg_chain_break_fraction = sum(chain_break_fractions_for_this_gamma) / num_runs_per_gamma\n",
    "    mean_chain_break_fractions.append(avg_chain_break_fraction)\n",
    "\n",
    "    print(f\"For gamma={gamma}, average chain break fraction over {num_runs_per_gamma} runs: {avg_chain_break_fraction}\")\n",
    "\n",
    "# Plot gamma values against mean chain break fractions\n",
    "plt.plot(gammas, mean_chain_break_fractions, '-o')\n",
    "plt.xlabel('Lagrange Parameter')\n",
    "plt.ylabel('Chain Break Fraction')\n",
    "#plt.title(f'Average Chain Break Fraction vs. Gamma (over {num_runs_per_gamma} runs)')\n",
    "#plt.grid(True)\n",
    "#plt.savefig('cbf_vs_gamma_s1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b5f36",
   "metadata": {},
   "source": [
    "## Pareto Front "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Weighted Pareto for single gamma-------\n",
    "num_reads = 1000\n",
    "gamma = 10000\n",
    "\n",
    "Q = defaultdict(int)\n",
    "\n",
    "# Fill in Q matrix\n",
    "for u, v in G.edges:\n",
    "    Q[(u,u)] += 1 * G[u][v][\"weight\"]\n",
    "    Q[(v,v)] += 1 * G[u][v][\"weight\"]\n",
    "    Q[(u,v)] += -2* G[u][v][\"weight\"]\n",
    "\n",
    "#for i in G.nodes:\n",
    "#    Q[(i,i)] += gamma*(1-len(G.nodes))*df.iloc[i,1]\n",
    "\n",
    "#for i, j in combinations(G.nodes, 2):\n",
    "#    Q[(i,j)] += 2*gamma*df.iloc[i,1]*df.iloc[j,1]\n",
    "\n",
    "for i in G.nodes:\n",
    "    Q[(i,i)] += gamma*(df.iloc[i,1]-df[1].sum())*df.iloc[i,1]\n",
    "\n",
    "for i, j in combinations(G.nodes, 2):\n",
    "    Q[(i,j)] += 2*gamma*df.iloc[i,1]*df.iloc[j,1]\n",
    "\n",
    "# ------- Run QUBO\n",
    "\n",
    "# Set chain strength\n",
    "chain_strength = gamma*len(G.nodes)\n",
    "\n",
    "# Run the QUBO on the solver from your config file\n",
    "sampler = EmbeddingComposite(DWaveSampler())\n",
    "response = sampler.sample_qubo(Q,\n",
    "                               chain_strength=chain_strength,\n",
    "                               num_reads=num_reads,\n",
    "                               label= 'Graph Partitioning')\n",
    "\n",
    "# See if the best solution found is feasible, and if so print the number of cut edges.\n",
    "f1=[]\n",
    "f2=[]\n",
    "for kk in range(0,len(response.record)):\n",
    "    sample = response.record.sample[kk]\n",
    "    fx2 = 0\n",
    "    for u, v in G.edges:\n",
    "        fx2 += (sample[u] + sample[v] - 2*sample[u]*sample[v])*G[u][v][\"weight\"][0]\n",
    "    f2.append(fx2)  \n",
    "    out_n=[0,26,24,25,20,18,19,23,21,22,8,6,7,2,1,5,3,4,17,15,16,11,9,10,14,12,13]\n",
    "    final=out_n\n",
    "    for i in range(0,27):\n",
    "        final[i]=sample[i]*df.iloc[out_n[i],1]\n",
    "    fx1=abs(sum(final)-df[1].sum())\n",
    "    f1.append(fx1)\n",
    "#dwave.inspector.show(response)       \n",
    "d_output=response.to_pandas_dataframe()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e466aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Weighted Pareto for looped gamma-------\n",
    "num_reads = 1000\n",
    "gamma = 10000\n",
    "#gamma_range=np.arange(100,5000,100) #Experimenting with different ranges\n",
    "#gamma_range=np.arange(0.05,20,0.2)\n",
    "gamma_range=np.arange(0.05,50,0.5)\n",
    "f1=[]\n",
    "f2=[]\n",
    "for gamma in gamma_range: \n",
    "    print(gamma)\n",
    "    Q = defaultdict(int)\n",
    "\n",
    "    # Fill in Q matrix\n",
    "    for u, v in G.edges:\n",
    "        Q[(u,u)] += 1 * G[u][v][\"weight\"]\n",
    "        Q[(v,v)] += 1 * G[u][v][\"weight\"]\n",
    "        Q[(u,v)] += -2* G[u][v][\"weight\"]\n",
    "\n",
    "#for i in G.nodes:\n",
    "#    Q[(i,i)] += gamma*(1-len(G.nodes))*df.iloc[i,1]\n",
    "\n",
    "#for i, j in combinations(G.nodes, 2):\n",
    "#    Q[(i,j)] += 2*gamma*df.iloc[i,1]*df.iloc[j,1]\n",
    "\n",
    "    for i in G.nodes:\n",
    "        Q[(i,i)] += gamma*(df.iloc[i,1]-df[1].sum())*df.iloc[i,1]\n",
    "\n",
    "    for i, j in combinations(G.nodes, 2):\n",
    "        Q[(i,j)] += 2*gamma*df.iloc[i,1]*df.iloc[j,1]\n",
    "\n",
    "# ------- Run our QUBO on the QPU -------\n",
    "\n",
    "# Set chain strength\n",
    "    chain_strength = gamma*len(G.nodes)\n",
    "\n",
    "# Run the QUBO \n",
    "    sampler = EmbeddingComposite(DWaveSampler(token='')) #Add your token\n",
    "    response = sampler.sample_qubo(Q,\n",
    "                                   chain_strength=chain_strength,\n",
    "                                   num_reads=num_reads,\n",
    "                                   label= 'Graph Partitioning')\n",
    "\n",
    "# See if the best solution found is feasible, and if so print the number of cut edges.\n",
    "    for kk in range(0,len(response.record)):  #Loop Through samples\n",
    "        sample = response.record.sample[kk]\n",
    "        fx2 = 0\n",
    "        for u, v in G.edges:\n",
    "            fx2 += (sample[u] + sample[v] - 2*sample[u]*sample[v])*G[u][v][\"weight\"][0] #Find weight of cuts\n",
    "        f2.append(fx2)                                                                  #Store\n",
    "        out_n=[0,26,24,25,20,18,19,23,21,22,8,6,7,2,1,5,3,4,17,15,16,11,9,10,14,12,13]  #Find weight of partition\n",
    "        final=out_n\n",
    "        for i in range(0,27):\n",
    "            final[i]=sample[i]*df.iloc[out_n[i],1]\n",
    "        #fx1=abs(sum(final)-df[1].sum())\n",
    "        fx1=abs(sum(final)-abs(sum(final)-df[1].sum()))/(0.5*df[1].sum())\n",
    "        f1.append(fx1)                                                                  #Store\n",
    "#dwave.inspector.show(response)       \n",
    "    d_output=response.to_pandas_dataframe()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27990d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debug Check\n",
    "#df[1].sum()\n",
    "#abs(sum(final)-df[1].sum())\n",
    "#sum(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debug check\n",
    "d_output=response.to_pandas_dataframe()  \n",
    "d_output\n",
    "plt.scatter(f1,f2)\n",
    "d_output\n",
    "len(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ddf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = pd.DataFrame(candidate_solutions, columns=['Imbalance', 'Cut Edge Weights'])\n",
    "# Save DataFrames to CSV\n",
    "df_candidates.to_csv('candidate_solutions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0230fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate pareto front from f1 and f2 candidate solutions\n",
    "def is_dominated(solution_a, solution_b):\n",
    "    \"\"\"\n",
    "    Check if solution_a is dominated by solution_b.\n",
    "    \"\"\"\n",
    "    a_obj1, a_obj2 = solution_a  # Objective values of solution_a\n",
    "    b_obj1, b_obj2 = solution_b  # Objective values of solution_b\n",
    "\n",
    "    return a_obj1 >= b_obj1 and a_obj2 >= b_obj2 and (a_obj1 > b_obj1 or a_obj2 > b_obj2)\n",
    "\n",
    "def find_pareto_front(candidate_solutions):\n",
    "    \"\"\"\n",
    "    Find the Pareto front from a list of candidate solutions.\n",
    "    \"\"\"\n",
    "    pareto_front = []\n",
    "    for solution in candidate_solutions:\n",
    "        is_dominated_by_others = False\n",
    "        for other_solution in candidate_solutions:\n",
    "            if solution != other_solution and is_dominated(solution, other_solution):\n",
    "                is_dominated_by_others = True\n",
    "                break\n",
    "        if not is_dominated_by_others:\n",
    "            pareto_front.append(solution)\n",
    "    return pareto_front\n",
    "candidate_solutions=list(zip(f1, f2))\n",
    "pareto_front = find_pareto_front(candidate_solutions)\n",
    "print(\"Pareto Front:\")\n",
    "#for solution in pareto_front:\n",
    "#    print(solution)\n",
    "#candidate_solutions\n",
    "x_values = [solution[0] for solution in pareto_front]\n",
    "y_values = [solution[1] for solution in pareto_front]\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.scatter(x_values, y_values,label=\"QA\")\n",
    "plt.scatter(0.189,5.2,label=\"METIS\")\n",
    "#plt.title(\"Pareto Front\")\n",
    "plt.xlabel(\"Solution Imbalance\")\n",
    "plt.ylabel(\"Cut Edge Weights\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"pareto_0.1_10.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9445394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming candidate_solutions, is_dominated, find_pareto_front functions, and METIS solution are defined\n",
    "\n",
    "# Find the Pareto front\n",
    "pareto_front = find_pareto_front(candidate_solutions)\n",
    "\n",
    "# Solutions that dominate the METIS solution, excluding those on the Pareto front\n",
    "dominates_metis = [sol for sol in candidate_solutions if is_dominated(metis_solution, sol) and sol not in pareto_front]\n",
    "\n",
    "# Sorting Pareto front points for line plot\n",
    "pareto_front_sorted = sorted(pareto_front, key=lambda x: x[0])  # Sort by the first objective (e.g., imbalance)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Pareto front points\n",
    "ax.scatter([sol[0] for sol in pareto_front], [sol[1] for sol in pareto_front], label='Pareto Front',zorder=5)\n",
    "# Connect Pareto front points with a line\n",
    "ax.plot([sol[0] for sol in pareto_front_sorted], [sol[1] for sol in pareto_front_sorted],linestyle=\"--\",zorder=4)\n",
    "\n",
    "# Solutions dominating METIS\n",
    "ax.scatter([sol[0] for sol in dominates_metis], [sol[1] for sol in dominates_metis], color='lightblue', label='Dominates METIS',marker=\".\")\n",
    "\n",
    "# METIS solution\n",
    "ax.scatter(*metis_solution, color='red', label='METIS', zorder=5)  # zorder for drawing order\n",
    "\n",
    "ax.set_xlim(left=-0.02, right=0.45)\n",
    "\n",
    "ax.legend()\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.xlabel(\"Solution Imbalance\")\n",
    "plt.ylabel(\"Cut Edge Weights\")\n",
    "plt\n",
    "plt.tight_layout\n",
    "plt.savefig(\"pareto_f2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same plot as above but includes all candidate solutions in light grey\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot all candidate solutions lightly for context\n",
    "candidates_plot = ax.scatter([sol[0] for sol in candidate_solutions], \n",
    "                             [sol[1] for sol in candidate_solutions], \n",
    "                             color='gray', alpha=0.01, marker=\"x\")\n",
    "\n",
    "# Pareto front points\n",
    "pareto_front_plot = ax.scatter([sol[0] for sol in pareto_front], \n",
    "                               [sol[1] for sol in pareto_front], \n",
    "                               label='Pareto Front', zorder=5)\n",
    "\n",
    "# Connect Pareto front points with a line\n",
    "ax.plot([sol[0] for sol in pareto_front_sorted], \n",
    "        [sol[1] for sol in pareto_front_sorted], \n",
    "        linestyle=\"--\", zorder=4)\n",
    "\n",
    "# Solutions dominating METIS (explicitly excluding Pareto front)\n",
    "dominates_metis_plot = ax.scatter([sol[0] for sol in dominates_metis], \n",
    "                                  [sol[1] for sol in dominates_metis], \n",
    "                                  color='lightblue', label='Dominates METIS', marker=\".\")\n",
    "\n",
    "# METIS solution\n",
    "metis_plot = ax.scatter(*metis_solution, color='red', label='METIS', zorder=5)  # zorder for drawing order\n",
    "\n",
    "# Create custom legend handles\n",
    "candidates_legend = mlines.Line2D([], [], color='gray', marker='x', linestyle='None',\n",
    "                                  markersize=8, label='Candidates',alpha=0.5)\n",
    "pareto_legend = mlines.Line2D([], [], marker='o', linestyle='None',\n",
    "                              markersize=10, label='Pareto Front')\n",
    "dominates_metis_legend = mlines.Line2D([], [], color='lightblue', marker='.', linestyle='None',\n",
    "                                        markersize=10, label='Dominates METIS')\n",
    "metis_legend = mlines.Line2D([], [], color='red', marker='o', linestyle='None',\n",
    "                              markersize=10, label='METIS')\n",
    "\n",
    "\n",
    "ax.legend(handles=[candidates_legend, pareto_legend, dominates_metis_legend, metis_legend])\n",
    "\n",
    "ax.set_xlim(left=-0.02, right=0.45)\n",
    "ax.set_ylim(bottom=2.5, top=6.0)\n",
    "plt.xlabel(\"Solution Quality\")\n",
    "plt.ylabel(\"Cut Edge Weights\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "#plt.savefig(\"pareto_f5.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dominates_metis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocean",
   "language": "python",
   "name": "ocean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
